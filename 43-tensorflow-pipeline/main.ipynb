{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales_number = [21, 22, -108, 31, -1, 32, 34, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_number)\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.take(5):\n",
    "\tprint(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "31\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.filter(lambda x:x>0)\n",
    "for sales in tf_dataset:\n",
    "\tprint(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512\n",
      "1584\n",
      "2232\n",
      "2304\n",
      "2448\n",
      "2232\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.map(lambda x: x*72)\n",
    "for sales in tf_dataset:\n",
    "\tprint(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512\n",
      "1584\n",
      "2232\n",
      "2304\n",
      "2448\n",
      "2232\n"
     ]
    }
   ],
   "source": [
    "tf_dataet = tf_dataset.shuffle(3)\n",
    "for sales in tf_dataset:\n",
    "\tprint(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1512 1584 2232 2304]\n",
      "[2448 2232]\n"
     ]
    }
   ],
   "source": [
    "for sales_batch in tf_dataset.batch(4):\n",
    "\tprint(sales_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1512 1584]\n",
      "[2304 2232]\n",
      "[2232 2448]\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.filter(lambda x: x>0).map(lambda y: y*72).shuffle(2).batch(2)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "\tprint(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pakai image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ds = tf.data.Dataset.list_files('./datasets/images/*/*', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(images_ds)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(images_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'.\\\\datasets\\\\images\\\\cat\\\\01.jpeg'\n",
      "b'.\\\\datasets\\\\images\\\\cat\\\\02.jpg'\n",
      "b'.\\\\datasets\\\\images\\\\cat\\\\03.jpg'\n"
     ]
    }
   ],
   "source": [
    "for file in images_ds.take(3):\n",
    "\tprint(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'.\\\\datasets\\\\images\\\\cat\\\\03.jpg'\n",
      "b'.\\\\datasets\\\\images\\\\dog\\\\01.jpg'\n",
      "b'.\\\\datasets\\\\images\\\\cat\\\\02.jpg'\n"
     ]
    }
   ],
   "source": [
    "images_ds = images_ds.shuffle(200)\n",
    "for file in images_ds.take(3):\n",
    "\tprint(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = [\"cat\", \"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(image_count*0.8)\n",
    "train_ds = images_ds.take(train_size)\n",
    "test_ds = images_ds.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "\timport os\n",
    "\tparts = tf.strings.split(file_path, os.path.sep)\n",
    "\treturn parts[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(file_path):\n",
    "\tlabel = get_label(file_path)\n",
    "\timg = tf.io.read_file(file_path)\n",
    "\timg = tf.image.decode_jpeg(img)\n",
    "\timg = tf.image.resize(img, [128, 128])\n",
    "\treturn img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'./datasets/images/cat/01.jpeg'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "parts = tf.strings.split(\"./datasets/images/cat/01.jpeg\", os.path.sep)\n",
    "parts.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = process_image(\"./datasets/images/cat/01.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ds = train_ds.map(process_image)\n",
    "test_ds = test_ds.map(process_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** tf.Tensor(\n",
      "[[[ 43.         78.         48.       ]\n",
      "  [ 43.         78.         48.       ]\n",
      "  [ 43.         80.         49.       ]\n",
      "  ...\n",
      "  [  6.2730103  30.27301    17.27301  ]\n",
      "  [  3.1083374  26.108337   16.108337 ]\n",
      "  [  4.         23.         17.       ]]\n",
      "\n",
      " [[ 43.         78.         48.       ]\n",
      "  [ 43.         78.         48.       ]\n",
      "  [ 44.81903    79.81903    49.81903  ]\n",
      "  ...\n",
      "  [  5.         27.         15.       ]\n",
      "  [  2.         23.         14.       ]\n",
      "  [  2.203125   21.203125   15.203125 ]]\n",
      "\n",
      " [[ 41.773438   78.         46.160156 ]\n",
      "  [ 43.         76.77344    46.160156 ]\n",
      "  [ 43.845886   75.00604    47.845886 ]\n",
      "  ...\n",
      "  [  5.3867188  25.386719   14.386719 ]\n",
      "  [  2.6262817  22.013      14.852844 ]\n",
      "  [  1.3081665  21.534729   14.921448 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[103.        137.79688    48.40625  ]\n",
      "  [106.        141.         49.       ]\n",
      "  [107.6037    143.59412    47.61328  ]\n",
      "  ...\n",
      "  [ 99.        141.         43.       ]\n",
      "  [ 99.        141.         39.       ]\n",
      "  [101.46918   143.46918    43.469177 ]]\n",
      "\n",
      " [[102.        139.         46.       ]\n",
      "  [103.        140.         44.       ]\n",
      "  [104.984375  142.98438    41.984375 ]\n",
      "  ...\n",
      "  [ 99.        141.         39.335938 ]\n",
      "  [101.        143.16797    40.664062 ]\n",
      "  [101.76276   143.76276    41.762756 ]]\n",
      "\n",
      " [[ 99.44531   142.27734    43.445312 ]\n",
      "  [ 99.44531   142.27734    40.       ]\n",
      "  [103.        146.         38.722656 ]\n",
      "  ...\n",
      "  [103.        144.         40.       ]\n",
      "  [101.        146.         43.       ]\n",
      "  [102.39557   146.66797    39.243835 ]]], shape=(128, 128, 3), dtype=float32)\n",
      "**** tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "**** tf.Tensor(\n",
      "[[[86.       75.       73.      ]\n",
      "  [86.41797  75.41797  73.41797 ]\n",
      "  [86.41797  75.41797  73.41797 ]\n",
      "  ...\n",
      "  [68.61572  66.24072  71.36572 ]\n",
      "  [68.41797  66.41797  71.41797 ]\n",
      "  [68.41797  66.41797  71.41797 ]]\n",
      "\n",
      " [[86.       75.       73.      ]\n",
      "  [84.25391  73.25391  71.25391 ]\n",
      "  [84.25391  73.25391  71.25391 ]\n",
      "  ...\n",
      "  [67.59717  65.22217  70.34717 ]\n",
      "  [67.25391  65.25391  70.25391 ]\n",
      "  [67.25391  65.25391  70.25391 ]]\n",
      "\n",
      " [[83.65869  72.65869  70.65869 ]\n",
      "  [84.20361  73.20361  71.20361 ]\n",
      "  [83.       72.       70.      ]\n",
      "  ...\n",
      "  [66.46484  64.08984  69.21484 ]\n",
      "  [66.08984  64.08984  69.08984 ]\n",
      "  [66.       64.       69.      ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[76.30762  68.30762  66.30762 ]\n",
      "  [99.59131  91.59131  89.59131 ]\n",
      "  [84.21484  74.21484  72.21484 ]\n",
      "  ...\n",
      "  [76.234375 66.359375 63.984375]\n",
      "  [88.34326  78.34326  77.34326 ]\n",
      "  [75.680176 65.680176 64.680176]]\n",
      "\n",
      " [[68.28125  60.28125  58.28125 ]\n",
      "  [82.16455  74.16455  72.16455 ]\n",
      "  [87.805176 77.805176 75.805176]\n",
      "  ...\n",
      "  [68.532715 58.625977 56.999023]\n",
      "  [61.645996 51.645996 50.645996]\n",
      "  [71.06738  61.257812 60.162598]]\n",
      "\n",
      " [[74.62842  64.62842  62.628418]\n",
      "  [89.899414 81.899414 79.899414]\n",
      "  [78.64746  70.64746  68.64746 ]\n",
      "  ...\n",
      "  [99.1167   89.3667   87.3667  ]\n",
      "  [92.99707  85.12207  82.62207 ]\n",
      "  [59.50586  53.50586  54.75586 ]]], shape=(128, 128, 3), dtype=float32)\n",
      "**** tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "**** tf.Tensor(\n",
      "[[[0.0000000e+00 2.4006729e+01 2.8006729e+01]\n",
      "  [0.0000000e+00 1.2682938e+01 2.1682938e+01]\n",
      "  [9.8197937e-01 1.4495834e+01 2.3495834e+01]\n",
      "  ...\n",
      "  [2.8427124e-01 1.7700104e+01 2.1842239e+01]\n",
      "  [0.0000000e+00 1.3723312e+01 2.0723312e+01]\n",
      "  [4.0798157e+01 3.0683792e+01 2.8648636e+01]]\n",
      "\n",
      " [[2.5097809e+00 2.7449219e+01 3.2449219e+01]\n",
      "  [3.7090607e+00 1.7709061e+01 2.6709061e+01]\n",
      "  [0.0000000e+00 1.0251251e+01 1.9251251e+01]\n",
      "  ...\n",
      "  [9.4656372e-01 2.0392502e+01 2.5392502e+01]\n",
      "  [1.9528198e-01 1.4208969e+01 2.0208969e+01]\n",
      "  [5.3157806e+00 3.7270874e+01 3.6270874e+01]]\n",
      "\n",
      " [[3.8326569e+00 2.3832657e+01 3.0832657e+01]\n",
      "  [1.1868744e+00 1.4186874e+01 2.3186874e+01]\n",
      "  [0.0000000e+00 1.1500519e+01 2.0500519e+01]\n",
      "  ...\n",
      "  [2.3905945e-01 2.3231506e+01 2.9231506e+01]\n",
      "  [0.0000000e+00 2.0789062e+01 2.4789062e+01]\n",
      "  [0.0000000e+00 3.3000000e+01 3.8000000e+01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[9.3929688e+01 9.0929688e+01 7.1929688e+01]\n",
      "  [1.0994812e+02 9.8948120e+01 8.0948120e+01]\n",
      "  [1.0850078e+02 9.1500778e+01 7.1500778e+01]\n",
      "  ...\n",
      "  [0.0000000e+00 1.4917709e+01 2.2917709e+01]\n",
      "  [0.0000000e+00 1.3320938e+01 2.1320938e+01]\n",
      "  [2.0703125e+00 1.9070312e+01 2.7070312e+01]]\n",
      "\n",
      " [[1.1025394e+02 9.5253937e+01 7.4253937e+01]\n",
      "  [1.0597644e+02 9.3976440e+01 6.9976440e+01]\n",
      "  [9.2338287e+01 7.9338287e+01 6.0338287e+01]\n",
      "  ...\n",
      "  [2.0187378e-01 1.6504059e+01 2.4504059e+01]\n",
      "  [6.0562134e-02 1.6076218e+01 2.4076218e+01]\n",
      "  [4.3099976e-01 1.2953842e+01 2.0953842e+01]]\n",
      "\n",
      " [[1.1394942e+02 9.8949417e+01 7.5949417e+01]\n",
      "  [9.3597031e+01 8.5597031e+01 6.6597031e+01]\n",
      "  [1.0249698e+02 9.1496979e+01 7.3496979e+01]\n",
      "  ...\n",
      "  [4.9936981e+00 2.1960052e+01 2.9960052e+01]\n",
      "  [0.0000000e+00 1.6472656e+01 2.4472656e+01]\n",
      "  [0.0000000e+00 1.2488281e+01 2.0488281e+01]]], shape=(128, 128, 3), dtype=float32)\n",
      "**** tf.Tensor(b'dog', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_ds.take(3):\n",
    "    print(\"****\",image)\n",
    "    print(\"****\",label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    return image/255, label\n",
    "\n",
    "train_ds = train_ds.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Image:  [0.1764706  0.03137255 0.0627451 ]\n",
      "****Label:  b'dog'\n",
      "****Image:  [0.3372549  0.29411766 0.28627452]\n",
      "****Label:  b'cat'\n",
      "****Image:  [0.1882353  0.1764706  0.14117648]\n",
      "****Label:  b'cat'\n",
      "****Image:  [0.16862746 0.30588236 0.1882353 ]\n",
      "****Label:  b'dog'\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_ds.take(5):\n",
    "    print(\"****Image: \",image.numpy()[0][0])\n",
    "    print(\"****Label: \",label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
