{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalisasi dataset\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e723967390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[523])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train_flattened = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
    "X_test_flattened = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n",
    "X_train_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2721 - accuracy: 0.9198\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1160 - accuracy: 0.9657\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0800 - accuracy: 0.9752\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0620 - accuracy: 0.9807\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0510 - accuracy: 0.9836\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0377 - accuracy: 0.9879\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0320 - accuracy: 0.9896\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0292 - accuracy: 0.9903\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0240 - accuracy: 0.9922\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0217 - accuracy: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e726c9d010>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train[0].shape[0], X_train[0].shape[1])),\n",
    "    #10 -> output, input shape itu jumlah neuran, y->klo input ada channelnya\n",
    "    keras.layers.Dense(100, input_shape=(X_train_flattened.shape[1], ), activation='relu'),\n",
    "    keras.layers.Dense(40, input_shape=(X_train_flattened.shape[1], ), activation='relu'),\n",
    "    keras.layers.Dense(10, input_shape=(X_train_flattened.shape[1], ), activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', #fungsi untuk mencapai global optima secara efisien ketika melakukan backward error propagation\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1001 - accuracy: 0.9746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10012032836675644, 0.9746000170707703]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post training quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"./saved_model\")\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334172"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"./saved_model\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87080"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"tflite_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "with open(\"tflite_quant_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Quantization aware training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer (QuantizeLa  (None, 28, 28)            3         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " quant_flatten (QuantizeWra  (None, 784)               1         \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense (QuantizeWrapp  (None, 100)               78505     \n",
      " erV2)                                                           \n",
      "                                                                 \n",
      " quant_dense_1 (QuantizeWra  (None, 40)                4045      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_2 (QuantizeWra  (None, 10)                415       \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82969 (324.10 KB)\n",
      "Trainable params: 82950 (324.02 KB)\n",
      "Non-trainable params: 19 (76.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "q_aware_model = quantize_model(model)\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 10s 4ms/step - loss: 0.0235 - accuracy: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e744abbbd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_aware_model.fit(X_train, y_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1079 - accuracy: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10791357606649399, 0.9753999710083008]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_aware_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ACER\\AppData\\Local\\Temp\\tmp42_gox34\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ACER\\AppData\\Local\\Temp\\tmp42_gox34\\assets\n",
      "c:\\Python311\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_qaware_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86888"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tflite_qaware_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tflite_qaware_model.tflite\", 'wb') as f:\n",
    "    f.write(tflite_qaware_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aware_lite = TensorflowLiteClassificationModel(\"path/to/model.tflite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
